{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Child Mind Institute - BFRB Detection\n",
    "## Final Submission with Parquet Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# For parquet support\n",
    "try:\n",
    "    import pyarrow\n",
    "    import pyarrow.parquet as pq\n",
    "    PARQUET_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Installing pyarrow for parquet support...\")\n",
    "    !pip install pyarrow --quiet\n",
    "    import pyarrow\n",
    "    import pyarrow.parquet as pq\n",
    "    PARQUET_AVAILABLE = True\n",
    "\n",
    "# Set competition path\n",
    "ZIP_PATH = '/path/to/cmi-detect-behavior-with-sensor-data.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class SensorProcessor:\n",
    "    \"\"\"Simple processor to extract sequence data\"\"\"\n",
    "    \n",
    "    def __init__(self, zip_path):\n",
    "        self.zip_path = zip_path\n",
    "    \n",
    "    def get_sequence_ids(self, file_path, max_chunks=None):\n",
    "        \"\"\"Extract unique sequence IDs from the CSV file\"\"\"\n",
    "        # Handle case where data isn't available\n",
    "        if not os.path.exists(self.zip_path):\n",
    "            print(\"Using mock sequence IDs.\")\n",
    "            return [f'SEQ_{i:04d}' for i in range(1, 11)]\n",
    "        \n",
    "        # Process real data\n",
    "        sequence_ids = []\n",
    "        with zipfile.ZipFile(self.zip_path, 'r') as zip_ref:\n",
    "            with zip_ref.open(file_path) as f:\n",
    "                chunks = pd.read_csv(f, chunksize=100000)\n",
    "                for i, chunk in enumerate(chunks):\n",
    "                    if max_chunks is not None and i >= max_chunks:\n",
    "                        break\n",
    "                    sequence_ids.extend(chunk['sequence_id'].unique())\n",
    "                    \n",
    "        return sorted(list(set(sequence_ids)))\n",
    "    \n",
    "    def extract_sequence(self, file_path, sequence_id):\n",
    "        \"\"\"Extract a specific sequence from the CSV file\"\"\"\n",
    "        # Handle case where data isn't available\n",
    "        if not os.path.exists(self.zip_path):\n",
    "            # Create a simple mock sequence\n",
    "            seq_num = int(sequence_id.split('_')[1])\n",
    "            is_target = seq_num % 2 == 1  # Odd numbers are targets\n",
    "            return {'is_target': is_target}\n",
    "        \n",
    "        # Process real data\n",
    "        sequence_df = None\n",
    "        with zipfile.ZipFile(self.zip_path, 'r') as zip_ref:\n",
    "            with zip_ref.open(file_path) as f:\n",
    "                chunks = pd.read_csv(f, chunksize=100000)\n",
    "                for chunk in chunks:\n",
    "                    seq_data = chunk[chunk['sequence_id'] == sequence_id]\n",
    "                    if len(seq_data) > 0:\n",
    "                        if sequence_df is None:\n",
    "                            sequence_df = seq_data\n",
    "                        else:\n",
    "                            sequence_df = pd.concat([sequence_df, seq_data])\n",
    "        \n",
    "        if sequence_df is not None:\n",
    "            return sequence_df\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def predict_gesture(self, sequence_data):\n",
    "        \"\"\"Make a prediction for a sequence\"\"\"\n",
    "        # For real implementation, use a trained model\n",
    "        # This is just a placeholder implementation\n",
    "        \n",
    "        # If we have a mock sequence\n",
    "        if isinstance(sequence_data, dict) and 'is_target' in sequence_data:\n",
    "            if sequence_data['is_target']:\n",
    "                # Choose a gesture for targets\n",
    "                gestures = ['hair_pull_scalp', 'hair_pull_eyebrow', 'skin_pick_face',\n",
    "                          'skin_pick_cuticle', 'hair_pull_eyelash']\n",
    "                return np.random.choice(gestures)\n",
    "            else:\n",
    "                return 'non_target'\n",
    "        \n",
    "        # If we have real sequence data\n",
    "        if isinstance(sequence_data, pd.DataFrame):\n",
    "            # Get sequence ID and use it for mock prediction\n",
    "            sequence_id = sequence_data['sequence_id'].iloc[0]\n",
    "            seq_num = int(sequence_id.split('_')[1]) if '_' in sequence_id else 0\n",
    "            \n",
    "            # Simple logic for demonstration\n",
    "            # In a real implementation, you would use extracted features and a trained model\n",
    "            if seq_num % 2 == 1:  # Odd numbers are targets\n",
    "                gestures = ['hair_pull_scalp', 'hair_pull_eyebrow', 'skin_pick_face',\n",
    "                          'skin_pick_cuticle', 'hair_pull_eyelash']\n",
    "                return gestures[seq_num % len(gestures)]\n",
    "            else:\n",
    "                return 'non_target'\n",
    "        \n",
    "        # Default fallback\n",
    "        return 'non_target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def generate_submission():\n",
    "    \"\"\"Generate a submission file in the required parquet format\"\"\"\n",
    "    processor = SensorProcessor(ZIP_PATH)\n",
    "    \n",
    "    # Get test sequence IDs (limit for demonstration)\n",
    "    test_ids = processor.get_sequence_ids('test.csv', max_chunks=1)\n",
    "    test_ids = test_ids[:10]\n",
    "    print(f\"Processing {len(test_ids)} test sequences...\")\n",
    "    \n",
    "    # Process each sequence\n",
    "    results = []\n",
    "    for seq_id in tqdm(test_ids):\n",
    "        # Extract sequence\n",
    "        sequence_data = processor.extract_sequence('test.csv', seq_id)\n",
    "        \n",
    "        # Make prediction\n",
    "        predicted_gesture = processor.predict_gesture(sequence_data)\n",
    "        \n",
    "        # Store result\n",
    "        results.append({\n",
    "            'sequence_id': seq_id,\n",
    "            'gesture': predicted_gesture\n",
    "        })\n",
    "        \n",
    "        # Free memory\n",
    "        del sequence_data\n",
    "        gc.collect()\n",
    "    \n",
    "    # Create DataFrame\n",
    "    submission_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Display preview\n",
    "    print(\"Preview of submission:\")\n",
    "    display(submission_df.head())\n",
    "    \n",
    "    # Save as parquet\n",
    "    output_file = 'submission.parquet'\n",
    "    submission_df.to_parquet(output_file, index=False)\n",
    "    \n",
    "    print(f\"Submission saved to {output_file}\")\n",
    "    \n",
    "    # Verify parquet file was created\n",
    "    if os.path.exists(output_file):\n",
    "        file_size = os.path.getsize(output_file) / 1024  # Size in KB\n",
    "        print(f\"Verified: {output_file} exists ({file_size:.2f} KB)\")\n",
    "        \n",
    "        # Read back to verify\n",
    "        test_df = pd.read_parquet(output_file)\n",
    "        print(f\"Successfully read back parquet file with {len(test_df)} rows\")\n",
    "    \n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# This is the main execution cell - Run this to create submission.parquet\n",
    "submission_df = generate_submission()\n",
    "\n",
    "# Display the final result again\n",
    "print(\"\\nFinal submission format:\")\n",
    "submission_df.info()\n",
    "submission_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
